# -*- coding: utf-8 -*-
"""Genai-WORD_EMBEDDING_TASK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ubgOB8tBOjgb6oVyUBoagzB8bxZyDr8-
"""

!pip install langchain sentence-transformers torch pandas numpy

!pip install -U langchain-community

import time
import numpy as np
import pandas as pd
from langchain.embeddings import HuggingFaceEmbeddings
from sklearn.metrics.pairwise import cosine_similarity

import time
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
except ImportError:
    print("[ERROR] langchain_community not installed correctly. Try restarting runtime and reinstalling.")

model_names = [
    "sentence-transformers/all-MiniLM-L6-v2",
    "sentence-transformers/all-mpnet-base-v2",
    "sentence-transformers/paraphrase-MiniLM-L3-v2",
    "sentence-transformers/distiluse-base-multilingual-cased-v2",
    "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"
]

sentence_pairs = [
    ("A man is eating food", "A person is eating a meal"),
    ("A dog is playing with a ball", "A child is playing with a toy"),
    ("The sky is blue", "The grass is green"),
    ("I love programming in Python", "Coding in Python is fun"),
    ("He went to the store", "He is shopping at a mall")
]

# Function to evaluate models dynamically with simple error handling
def evaluate_embeddings(model_name, pairs):
    try:
        embeddings = HuggingFaceEmbeddings(model_name=model_name)
    except Exception as e:
        print(f"[ERROR] Failed to load model '{model_name}': {e}")
        return None, None

    similarities = []
    start_time = time.time()

    for (s1, s2) in pairs:
        try:
            emb1 = embeddings.embed_query(s1)
            emb2 = embeddings.embed_query(s2)
            sim = cosine_similarity([emb1], [emb2])[0][0]
            similarities.append(sim)
        except Exception as e:
            print(f"[WARNING] Skipped pair ({s1[:20]}..., {s2[:20]}...): {e}")
            continue

    end_time = time.time()

    if not similarities:
        print(f"[ERROR] No valid similarities computed for model '{model_name}'")
        return None, end_time - start_time

    avg_sim = np.mean(similarities)
    latency = end_time - start_time

    return avg_sim, latency

#  Run evaluation for all models
results = []

for name in model_names:
    print(f"\nðŸ”¹ Evaluating: {name}")
    avg_sim, latency = evaluate_embeddings(name, sentence_pairs)
    if avg_sim is not None:
        results.append({"Model": name, "Avg_Similarity": avg_sim, "Latency_sec": latency})
        print(f"  Avg Similarity: {avg_sim:.4f} |  Latency: {latency:.2f} sec")
    else:
        print(f"  Skipped {name} due to an error.")

#  Create a results DataFrame
if results:
    df = pd.DataFrame(results).sort_values(by="Avg_Similarity", ascending=False)
    df.reset_index(drop=True, inplace=True)
    display(df)
else:
    print("[ERROR] No models were successfully evaluated.")

#  Small Semantic Search Example
try:
    query = "How to learn programming?"
    corpus = [
        "Python is great for beginners",
        "The sun rises in the east",
        "Programming involves problem solving",
        "Cooking recipes can be fun"
    ]

    # Use best model from above (top-ranked)
    if 'df' in locals() and not df.empty:
        best_model = df.iloc[0]["Model"]
        print(f"\n Using best model for search: {best_model}")

        embeddings = HuggingFaceEmbeddings(model_name=best_model)
        query_emb = embeddings.embed_query(query)
        corpus_embs = [embeddings.embed_query(text) for text in corpus]

        scores = [cosine_similarity([query_emb], [emb])[0][0] for emb in corpus_embs]

        print("\n Search Results (sorted by similarity):\n")
        for text, score in sorted(zip(corpus, scores), key=lambda x: x[1], reverse=True):
            print(f"{text}  â†’  Score: {score:.4f}")
    else:
        print("[ERROR] Results DataFrame is empty. No model to use for semantic search.")

except Exception as e:
    print(f"[ERROR] Failed during semantic search: {e}")

